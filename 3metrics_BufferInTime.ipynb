{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "from tqdm import tqdm\n",
    "import scipy.ndimage as snd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This looks at the begining and end of the precipitation accumulation period and selects the larger value of whichever metric\n",
    "#No adjacent grid points are considered\n",
    "size_mat1 = (2,1,1)\n",
    "origin_mat1 = (-1,0,0)\n",
    "# Same as above but adjacent grid points are considered (including diagonals)\n",
    "size_mat2 = (2,3,3)\n",
    "origin_mat2 = (-1,0,0)\n",
    "# FOR CAPE OnNLY, Look at the previous time or current time and no surrounding grid points\n",
    "cape_size_mat = (2,1,1)\n",
    "cape_origin_mat = (0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cape_dat = xr.open_dataset(path+'CAPE_consumption_percentile.nc')\n",
    "\n",
    "# select the largest score from surrounding grid points and times\n",
    "# We don't need to worry about scores in the edges, spatially because there are no extreme events there.\n",
    "# we do need to worry about the first and last time step\n",
    "\n",
    "cape_buffer = snd.maximum_filter(cape_dat['CAPE_consumption_percentile'],size=cape_size_mat,origin=cape_origin_mat,mode='constant',cval=0.)\n",
    "cape_dat['CAPE_consumption_percentile_Buffer'+str(cape_size_mat[0])+'x'+str(cape_size_mat[1])+'x'+str(cape_size_mat[2])] = (['time','latitude','longitude'],cape_buffer)\n",
    "cape_dat.to_netcdf(path+'CAPE_consumption_percentile-buffer.nc',mode='w')\n",
    "cape_dat.close()\n",
    "del cape_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frt_dat = xr.open_dataset(path+'gradEPT_Frontal_percentile.nc')\n",
    "\n",
    "# select the largest score from surrounding grid points and times\n",
    "# We don't need to worry about scores in the edges, spatially because there are no extreme events there.\n",
    "# we do need to worry about the first and last time step\n",
    "\n",
    "frt_buffer = snd.maximum_filter(frt_dat['gradEPT_percentile_AboveMedian'],size=(3,3,3),mode='constant',cval=0.)\n",
    "frt_dat['gradEPT_percentile_AboveMedian_Buffer3x3x3'] = (['time','latitude','longitude'],frt_buffer)\n",
    "frt_buffer = snd.maximum_filter(frt_dat['gradEPT_percentile_AboveMedian'],size=size_mat1,origin=origin_mat1,mode='constant',cval=0.)\n",
    "frt_dat['gradEPT_percentile_AboveMedian_Buffer'+str(size_mat1[0])+'x'+str(size_mat1[1])+'x'+str(size_mat1[2])] = (['time','latitude','longitude'],frt_buffer)\n",
    "frt_buffer = snd.maximum_filter(frt_dat['gradEPT_percentile_AboveMedian'],size=size_mat2,origin=origin_mat2,mode='constant',cval=0.)\n",
    "frt_dat['gradEPT_percentile_AboveMedian_Buffer'+str(size_mat2[0])+'x'+str(size_mat2[1])+'x'+str(size_mat2[2])] = (['time','latitude','longitude'],frt_buffer)\n",
    "frt_dat.to_netcdf(path+'gradEPT_Frontal_percentile-buffer.nc',mode='w')\n",
    "frt_dat.close()\n",
    "del frt_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrt_dat = xr.open_dataset(path+'PositiveRelativeVorticityAdvection_Percentile.nc')\n",
    "\n",
    "# select the largest score from surrounding grid points and times\n",
    "# We don't need to worry about scores in the edges, spatially because there are no extreme events there.\n",
    "# we do need to worry about the first and last time step\n",
    "\n",
    "vrt_buffer = snd.maximum_filter(vrt_dat['PositiveRelativeVorticityAdvection_Percentile'],size=(3,3,3),mode='constant',cval=0.)\n",
    "vrt_dat['PositiveRelativeVorticityAdvection_Percentile_Buffer3x3x3'] = (['time','latitude','longitude'],vrt_buffer)\n",
    "\n",
    "vrt_buffer = snd.maximum_filter(vrt_dat['PositiveRelativeVorticityAdvection_Percentile'],size=size_mat1,origin=origin_mat1,mode='constant',cval=0.)\n",
    "vrt_dat['PositiveRelativeVorticityAdvection_Percentile_Buffer'+str(size_mat1[0])+'x'+str(size_mat1[1])+'x'+str(size_mat1[2])] = (['time','latitude','longitude'],vrt_buffer)\n",
    "vrt_buffer = snd.maximum_filter(vrt_dat['PositiveRelativeVorticityAdvection_Percentile'],size=size_mat2,origin=origin_mat2,mode='constant',cval=0.)\n",
    "vrt_dat['PositiveRelativeVorticityAdvection_Percentile_Buffer'+str(size_mat2[0])+'x'+str(size_mat2[1])+'x'+str(size_mat2[2])] = (['time','latitude','longitude'],vrt_buffer)\n",
    "\n",
    "vrt_dat.to_netcdf(path+'PositiveRelativeVorticityAdvection_Percentile-buffer.nc',mode='w')\n",
    "vrt_dat.close()\n",
    "del vrt_buffer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrt_dat = xr.open_dataset(path+'PositiveTotalVorticityAdvection_Percentile.nc')\n",
    "\n",
    "# select the largest score from surrounding grid points and times\n",
    "# We don't need to worry about scores in the edges, spatially because there are no extreme events there.\n",
    "# we do need to worry about the first and last time step\n",
    "\n",
    "vrt_buffer = snd.maximum_filter(vrt_dat['PositiveTotalVorticityAdvection_Percentile'],size=(3,3,3),mode='constant',cval=0.)\n",
    "vrt_dat['PositiveTotalVorticityAdvection_Percentile_Buffer3x3x3'] = (['time','latitude','longitude'],vrt_buffer)\n",
    "\n",
    "vrt_buffer = snd.maximum_filter(vrt_dat['PositiveTotalVorticityAdvection_Percentile'],size=size_mat1,origin=origin_mat1,mode='constant',cval=0.)\n",
    "vrt_dat['PositiveTotalVorticityAdvection_Percentile_Buffer'+str(size_mat1[0])+'x'+str(size_mat1[1])+'x'+str(size_mat1[2])] = (['time','latitude','longitude'],vrt_buffer)\n",
    "vrt_buffer = snd.maximum_filter(vrt_dat['PositiveTotalVorticityAdvection_Percentile'],size=size_mat2,origin=origin_mat2,mode='constant',cval=0.)\n",
    "vrt_dat['PositiveTotalVorticityAdvection_Percentile_Buffer'+str(size_mat2[0])+'x'+str(size_mat2[1])+'x'+str(size_mat2[2])] = (['time','latitude','longitude'],vrt_buffer)\n",
    "\n",
    "vrt_dat.to_netcdf(path+'PositiveTotalVorticityAdvection_Percentile-buffer.nc',mode='w')\n",
    "vrt_dat.close()\n",
    "del vrt_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = np.zeros((5,5,5))\n",
    "# test[2,2,2] = 1\n",
    "# test[1,2,2] = 2\n",
    "# filt = snd.maximum_filter(test,size=(2,1,1),mode='constant',origin=(0,0,0),cval=0.)\n",
    "# print(test)\n",
    "# print(\"\")\n",
    "# print(\"SEP\")\n",
    "# print(\"\")\n",
    "# print(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
